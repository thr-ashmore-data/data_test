{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Activation, Embedding, Flatten, Dropout, Conv1D, MaxPooling1D, GlobalMaxPooling1D, Bidirectional\n",
    "from keras import backend\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras import optimizers\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from sklearn.model_selection import KFold\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Phoneme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>manicure-set</td>\n",
       "      <td>mæn.ɪ.kjʊə.set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>zairean</td>\n",
       "      <td>zaɪɪə.ri.ən</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embark-on-upon-something</td>\n",
       "      <td>ɪmbɑrk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>glycol</td>\n",
       "      <td>ɡlaɪ.kɒl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sublimate</td>\n",
       "      <td>sʌb.lɪ.meɪt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Word         Phoneme\n",
       "0              manicure-set  mæn.ɪ.kjʊə.set\n",
       "1                   zairean     zaɪɪə.ri.ən\n",
       "2  embark-on-upon-something          ɪmbɑrk\n",
       "3                    glycol        ɡlaɪ.kɒl\n",
       "4                 sublimate     sʌb.lɪ.meɪt"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#additional phonetics: numbers and acronyms etc. rename columns for concat\n",
    "x = pd.read_csv('C:/Users/ian.ashmore/Desktop/new_phon_train2.csv')\n",
    "x['Phoneme'] = x['Phoneme'].str[1:-1]\n",
    "dfx = pd.read_csv('C:/Users/ian.ashmore/Downloads/nums.csv', usecols=['numeric', 'uk'])\n",
    "dfx['uk'] = dfx['uk'].str[1:-1]\n",
    "dfx['uk'] = dfx['uk'].str.replace('ˈ','').str.replace('ˌ','').str.strip()\n",
    "dfx = dfx.rename(columns={'numeric':'Word', 'uk':'Phoneme'})\n",
    "dfx = dfx[~dfx.Word.isin(df.Word)]\n",
    "\n",
    "#FULL phoneme dataset (scraped from dictonary.com using beautiful soup for python)\n",
    "df = pd.read_csv('C:/Users/ian.ashmore/Downloads/charlie_EXTENDED_TS.csv')\n",
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df = df[~df.Phoneme.str.contains('x')]\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Phoneme</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47270</th>\n",
       "      <td>coming-of-age</td>\n",
       "      <td>kʌm.ɪŋ.əv.eɪdʒ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29652</th>\n",
       "      <td>father-confessor</td>\n",
       "      <td>fɑː.ðə.kənfes.ər</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38162</th>\n",
       "      <td>child-free</td>\n",
       "      <td>tʃaɪld.friː</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>held</td>\n",
       "      <td>held</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>cloistered</td>\n",
       "      <td>klɔɪ.stəd</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word           Phoneme\n",
       "47270     coming-of-age    kʌm.ɪŋ.əv.eɪdʒ\n",
       "29652  father-confessor  fɑː.ðə.kənfes.ər\n",
       "38162        child-free       tʃaɪld.friː\n",
       "6819               held              held\n",
       "10688        cloistered         klɔɪ.stəd"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concatenate dataframes into one, drop duplicates and shuffle:\n",
    "df2 = pd.concat([df, x, dfx], axis=0, ignore_index=True)\n",
    "df2 = df2.drop_duplicates(subset=['Word']).reset_index(drop=True)\n",
    "df2 = df2.sample(frac=1)\n",
    "\n",
    "#clean phoneme set to remove ambiguities between UK & US pronunciations and drop phonemes that are too 'subtle' for rap music\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('ɝ','ɜ')\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('aː','æ')\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('lː','lɪ')\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('tː','t')\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('ʃː','ʃ')\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('zː','z')\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('ɒː','ɔː')\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('əː','ə.')\n",
    "df2['Phoneme'] = df2.Phoneme.str.replace('ɪː','iː')\n",
    "\n",
    "#fix unique problem from scrape with below char\n",
    "for index, row in df2.iterrows():\n",
    "    row.Phoneme = row.Phoneme.replace('ɪɪ', 'ɪ.ɪ')  \n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Phoneme</th>\n",
       "      <th>combined_phons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47270</th>\n",
       "      <td>coming-of-age</td>\n",
       "      <td>kʌm.ɪŋ.əv.eɪdʒ</td>\n",
       "      <td>[k, ʌ, m, ., ɪ, ŋ, ., ə, v, ., e, ɪ, d, ʒ]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29652</th>\n",
       "      <td>father-confessor</td>\n",
       "      <td>fɑː.ðə.kənfes.ər</td>\n",
       "      <td>[f, ɑː, ., ð, ə, ., k, ə, n, f, e, s, ., ə, r]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38162</th>\n",
       "      <td>child-free</td>\n",
       "      <td>tʃaɪld.friː</td>\n",
       "      <td>[t, ʃ, a, ɪ, l, d, ., f, r, iː]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6819</th>\n",
       "      <td>held</td>\n",
       "      <td>held</td>\n",
       "      <td>[h, e, l, d]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10688</th>\n",
       "      <td>cloistered</td>\n",
       "      <td>klɔɪ.stəd</td>\n",
       "      <td>[k, l, ɔɪ, ., s, t, ə, d]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Word           Phoneme  \\\n",
       "47270     coming-of-age    kʌm.ɪŋ.əv.eɪdʒ   \n",
       "29652  father-confessor  fɑː.ðə.kənfes.ər   \n",
       "38162        child-free       tʃaɪld.friː   \n",
       "6819               held              held   \n",
       "10688        cloistered         klɔɪ.stəd   \n",
       "\n",
       "                                       combined_phons  \n",
       "47270      [k, ʌ, m, ., ɪ, ŋ, ., ə, v, ., e, ɪ, d, ʒ]  \n",
       "29652  [f, ɑː, ., ð, ə, ., k, ə, n, f, e, s, ., ə, r]  \n",
       "38162                 [t, ʃ, a, ɪ, l, d, ., f, r, iː]  \n",
       "6819                                     [h, e, l, d]  \n",
       "10688                       [k, l, ɔɪ, ., s, t, ə, d]  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#identify phonemes with double character represetnation (to allow them to produce a single token)\n",
    "doubles = ['iː', 'uː', 'ɔː', 'ɜː', 'ɑː', 'æː', 'ɔɪ', 'ʊː']\n",
    "\n",
    "#create empty lists for unique phonics and input sequences\n",
    "combined_phons = []\n",
    "unique_phons = []\n",
    "\n",
    "#iterate through dataframe and extract unique phonics and split training set into sequences\n",
    "for index, row in df2.iterrows():\n",
    "    x = row.Phoneme\n",
    "    phon_vals = [i for i in x]\n",
    "    phon_sets = [''.join(x[i:i+2]) for i in range(len(x))]\n",
    "    new_phon = []\n",
    "    for y, combination in enumerate(phon_sets):\n",
    "        if combination in doubles:\n",
    "            new_phon.append(str(combination))\n",
    "            if combination not in unique_phons:\n",
    "                unique_phons.append(combination)\n",
    "        else:\n",
    "            new_phon.append(str(combination[0])) \n",
    "            if combination[0] not in unique_phons:\n",
    "                unique_phons.append(combination[0])\n",
    "    final_phon = []\n",
    "    nxt=False\n",
    "    for phon in new_phon:\n",
    "        if len(phon)>1:\n",
    "            final_phon.append(phon)\n",
    "            nxt=True\n",
    "        elif phon == 'ɔ':\n",
    "            phon = 'ɔː'\n",
    "            final_phon.append(phon)\n",
    "            nxt=False\n",
    "        else:\n",
    "            if nxt==False:\n",
    "                final_phon.append(phon)\n",
    "            else:\n",
    "                nxt=False\n",
    "    combined_phons.append(final_phon)\n",
    "    \n",
    "df2['combined_phons'] = combined_phons\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input chars: ['t', ' ', 'z', 'e', '2', '6', 'x', 'q', 'r', 'p', '4', 'm', 'c', 'd', 'v', 'i', 'b', 'y', '8', '-', 'n', '7', 's', '9', 'k', 'u', 'f', 'h', 'g', '0', 'a', 'j', 'o', '3', '1', '5', 'l', 'w']\n",
      "input token index length 38\n"
     ]
    }
   ],
   "source": [
    "df3 = df2.sample(frac=1)\n",
    "#create input and target lists.\n",
    "input_texts = list(df3['Word'])\n",
    "target_texts = df3['combined_phons']\n",
    "\n",
    "#create \n",
    "input_chars = []\n",
    "for word in input_texts:\n",
    "    for char in word:\n",
    "        if char not in input_chars:\n",
    "            input_chars.append(char)\n",
    "            \n",
    "input_chars.append(' ')\n",
    "input_chars = list(set(input_chars))\n",
    "print(\"input chars:\", input_chars)\n",
    "\n",
    "#create dictionary to translate input characters to integers\n",
    "input_token_index = dict([(char, i) for i, char in enumerate(input_chars)])\n",
    "reverse_input_token_index = dict((i, char) for char, i in input_token_index.items())\n",
    "print(\"input token index length\", len(input_token_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['k', 'ʌ', 'm', '.', 'ɪ', 'ŋ', 'ə', 'v', 'e', 'd', 'ʒ', 'f', 'ɑː', 'ː', 'ð', 'n', 's', 'r', 't', 'ʃ', 'a', 'l', 'iː', 'h', 'ɔɪ', 'θ', 'ɜː', 'i', 'uː', 'p', 'æ', 'j', 'z', 'ʊ', 'ɒ', 'ɡ', 'ɔː', 'w', 'b', 'u', 'ɑ', 'ɚ', 'o', 'ɔ', 'ɜ', 'æː', 'ʊː']\n",
      "target token index length 47\n"
     ]
    }
   ],
   "source": [
    "#create dictionary to translate output characters to integers\n",
    "target_token_index = dict([(char, i) for i, char in enumerate(unique_phons)])\n",
    "reverse_target_token_index = dict((i, char) for char, i in target_token_index.items())\n",
    "print(unique_phons)\n",
    "print(\"target token index length\", len(target_token_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 54611\n",
      "input token index length: 38\n",
      "target token index length: 47\n",
      "Max sequence length for inputs: 46\n",
      "Max sequence length for outputs: 64\n",
      "maximum input length: 64\n"
     ]
    }
   ],
   "source": [
    "#details on training set:\n",
    "\n",
    "input_characters = sorted(list(input_chars))\n",
    "target_characters = sorted(list(unique_phons))\n",
    "num_encoder_tokens = len(input_token_index)\n",
    "num_decoder_tokens = len(target_token_index)\n",
    "max_encoder_seq_length = max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length = max([len(txt) for txt in target_texts])\n",
    "max_len = max(max_encoder_seq_length, max_decoder_seq_length)\n",
    "\n",
    "print('Number of samples:', len(input_texts)) #number of training examples\n",
    "print('input token index length:', len(input_token_index)) #number of input tokens\n",
    "print('target token index length:', len(target_token_index)) #number of output tokens\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length) #maximum length of input word\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length) #maximum length of output word\n",
    "print('maximum input length:', max_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder input shape: (50515, 64) target shape: (50515, 64, 47)\n"
     ]
    }
   ],
   "source": [
    "#split data set into training and validation sets.\n",
    "txtin_train, txtin_val, txtout_train, txtout_val = train_test_split(input_texts, target_texts, test_size=0.075)\n",
    "\n",
    "#create empty arrays for training and validation data\n",
    "encoder_input_data_train = np.zeros((len(txtin_train), max_len),dtype='float32')\n",
    "decoder_input_data_train = np.zeros((len(txtin_train), max_len),dtype='float32')\n",
    "encoder_input_data_val = np.zeros((len(txtin_val), max_len),dtype='float32')\n",
    "decoder_input_data_val = np.zeros((len(txtin_val), max_len),dtype='float32')\n",
    "target_data_train = np.zeros((len(txtout_train), max_len, len(target_token_index)), dtype='float32')\n",
    "target_data_val = np.zeros((len(txtout_val), max_len, len(target_token_index)), dtype='float32')\n",
    "\n",
    "\n",
    "for i, (txt_in, txt_out) in enumerate(zip(txtin_train, txtout_train)):\n",
    "    for t, char in enumerate(txt_in):\n",
    "        encoder_input_data_train[i,t] = input_token_index[char]\n",
    "    encoder_input_data_train[i,t+1:] = input_token_index[' ']\n",
    "    \n",
    "for i, (txt_in, txt_out) in enumerate(zip(txtin_val, txtout_val)):\n",
    "    for t, char in enumerate(txt_in):\n",
    "        encoder_input_data_val[i,t] = input_token_index[char]\n",
    "    encoder_input_data_val[i,t+1:] = input_token_index[' ']\n",
    "\n",
    "for i, (decoder_data) in enumerate(decoder_input_data_train):\n",
    "    for t, char in enumerate(decoder_data):\n",
    "        new_in = int(char)\n",
    "    target_data_train[i,t,new_in] = 1.\n",
    "    \n",
    "for i, (decoder_data) in enumerate(decoder_input_data_val):\n",
    "    for t, char in enumerate(decoder_data):\n",
    "        new_in = int(char)\n",
    "    target_data_val[i,t,new_in] = 1.\n",
    "    \n",
    "print(\"encoder input shape:\", encoder_input_data_train.shape, \"target shape:\", target_data_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_13 (Embedding)     (None, 64, 600)           23400     \n",
      "_________________________________________________________________\n",
      "bidirectional_27 (Bidirectio (None, 64, 1600)          8966400   \n",
      "_________________________________________________________________\n",
      "bidirectional_28 (Bidirectio (None, 64, 1600)          15366400  \n",
      "_________________________________________________________________\n",
      "bidirectional_29 (Bidirectio (None, 64, 1600)          15366400  \n",
      "_________________________________________________________________\n",
      "time_distributed_15 (TimeDis (None, 64, 400)           640400    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64, 400)           0         \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 64, 400)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_16 (TimeDis (None, 64, 46)            18446     \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 64, 46)            0         \n",
      "=================================================================\n",
      "Total params: 40,381,446\n",
      "Trainable params: 40,381,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#assign deep learning parameters\n",
    "vocab = len(input_token_index)+1\n",
    "w_dim = 600         #dimensionality of word vector embeddings\n",
    "latent_dim = 800    #hidden states inside lstm gates (equivalent to hidden nodes in densely connected layers)\n",
    "                    #NOTE THIS NUMBER IS DOUBLED BECAUSE THE WE ARE USING BI-DIRECTIONAL LSTM: 800 IN EACH DIR\n",
    "hidden = 400        #nodes in densely conected layer\n",
    "epochs = 1000       # maximum epocs\n",
    "batch_size = 64     #batch size of input: samples sent through before each back propagation pass\n",
    "num_steps = max_len\n",
    "num_epochs = epochs\n",
    "\n",
    "#callback to halt training if validation loss stops decreasing and restore the best score\n",
    "Callbacks = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=5e-8, patience=3, verbose=0, mode='auto', restore_best_weights=True)\n",
    "\n",
    "#create deep learning model: uses keras api: sequential model, model with tensorflow backend\n",
    "model8 = Sequential()\n",
    "#embedding layer converts input tokens to 300 dimensional vectors, initialised with random floats (trained with NN)\n",
    "model8.add(Embedding(vocab, w_dim, input_shape=(encoder_input_data_train[0].shape), trainable=True))\n",
    "#triple stacked bi-directional lstm layers, set to RETURN SEQ, (for sequential output)\n",
    "model8.add(Bidirectional(LSTM(latent_dim, return_sequences=True, dropout=0.15)))\n",
    "model8.add(Bidirectional(LSTM(latent_dim, return_sequences=True, dropout=0.15)))\n",
    "model8.add(Bidirectional(LSTM(latent_dim, return_sequences=True, dropout=0.15)))\n",
    "#time dependent hidden dense layer assists classification while retaining sequential nature of input\n",
    "model8.add(TimeDistributed(Dense(hidden)))\n",
    "model8.add(Dropout(0.25))\n",
    "model8.add(Activation('tanh'))\n",
    "#time dependent output layer predicts a sequence max_len long\n",
    "model8.add(TimeDistributed(Dense(len(target_token_index)), input_shape=(max_len,len(target_token_index))))\n",
    "model8.add(Activation('softmax'))\n",
    "print(model8.summary())\n",
    "\n",
    "#compile model with optimiser and loss function\n",
    "model8.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This would train the model, but needs GPU so instead load trained model below\n",
    "\n",
    "##history = model8.fit(encoder_input_data_train, target_data_train,\n",
    "#                     batch_size=batch_size,\n",
    "#                     shuffle=True,\n",
    "#                     epochs=epochs,\n",
    "#                     validation_data=[encoder_input_data_val,target_data_val], \n",
    "#                     callbacks=[Callbacks])\n",
    "##evaluate the model\n",
    "#score, acc = model8.evaluate(encoder_input_data_val, target_data_val, batch_size=64, verbose=1)\n",
    "\n",
    "#print('loss:', score, \"accuracy:\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 64, 600)           23400     \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 64, 1600)          8966400   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 64, 1600)          15366400  \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 64, 1600)          15366400  \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 64, 400)           640400    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 64, 400)           0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64, 400)           0         \n",
      "_________________________________________________________________\n",
      "time_distributed_6 (TimeDist (None, 64, 46)            18446     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 64, 46)            0         \n",
      "=================================================================\n",
      "Total params: 40,381,446\n",
      "Trainable params: 40,381,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#load pre-trained model and encoders\n",
    "\n",
    "model = keras.models.load_model('C:/Users/ian.ashmore/Desktop/MLD_1001/phoneme_translation_model_POINT1001.h5')\n",
    "print(model.summary())\n",
    "\n",
    "with open('C:/Users/ian.ashmore/Desktop/MLD_1001/input_token_index.pickle', 'rb') as handle:\n",
    "    input_token_index = pickle.load(handle)\n",
    "\n",
    "with open('C:/Users/ian.ashmore/Desktop/MLD_1001/reverse_input_token_index.pickle', 'rb') as handle:\n",
    "    reverse_input_token_index = pickle.load(handle)\n",
    "\n",
    "with open('C:/Users/ian.ashmore/Desktop/MLD_1001/target_token_index.pickle', 'rb') as handle:\n",
    "    target_token_index = pickle.load(handle)\n",
    "\n",
    "with open('C:/Users/ian.ashmore/Desktop/MLD_1001/reverse_target_token_index.pickle', 'rb') as handle:\n",
    "    reverse_target_token_index = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54611\n"
     ]
    }
   ],
   "source": [
    "#create a dictionary of words:phonemes, initially with the training set, but to be appended.\n",
    "phon_dict = dict(zip(df3.Word,df3.Phoneme))\n",
    "print(len(phon_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/lyric/5564459/Nellyville</td>\n",
       "      <td>[welcome to nellyville, where all newborns get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/lyric/24660518/Gettin%27+It+Started</td>\n",
       "      <td>[hey, boo, wassup?, you lookin' good, thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/lyric/5564461/Hot+in+Herre</td>\n",
       "      <td>[hot in, so hot in here! so hot in, hot, oh!, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/lyric/5564462/Dem+Boyz</td>\n",
       "      <td>[like, oh, better get them back, watch them ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/lyric/5564463/Oh+Nelly</td>\n",
       "      <td>[here we go again, real smooth, yeah, here we ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   song  \\\n",
       "0             /lyric/5564459/Nellyville   \n",
       "1  /lyric/24660518/Gettin%27+It+Started   \n",
       "2           /lyric/5564461/Hot+in+Herre   \n",
       "3               /lyric/5564462/Dem+Boyz   \n",
       "4               /lyric/5564463/Oh+Nelly   \n",
       "\n",
       "                                              lyrics  \n",
       "0  [welcome to nellyville, where all newborns get...  \n",
       "1  [hey, boo, wassup?, you lookin' good, thank yo...  \n",
       "2  [hot in, so hot in here! so hot in, hot, oh!, ...  \n",
       "3  [like, oh, better get them back, watch them ni...  \n",
       "4  [here we go again, real smooth, yeah, here we ...  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load songs - scraped from lyrics.com: extensively preprocessed elsewhere\n",
    "df_songs = pd.read_pickle(\"C:/Users/ian.ashmore/Desktop/81k_songs.pkl\")\n",
    "df_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lyrics_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/lyric/5564459/Nellyville</td>\n",
       "      <td>[welcome to nellyville, where all newborns get...</td>\n",
       "      <td>[welcome to nellyville, where all newborns get...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/lyric/24660518/Gettin%27+It+Started</td>\n",
       "      <td>[hey, boo, wassup?, you lookin' good, thank yo...</td>\n",
       "      <td>[hey, boo, wassup?, you lookin' good, thank yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/lyric/5564461/Hot+in+Herre</td>\n",
       "      <td>[hot in, so hot in here! so hot in, hot, oh!, ...</td>\n",
       "      <td>[hot in, so hot in here! so hot in, hot, oh!, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/lyric/5564462/Dem+Boyz</td>\n",
       "      <td>[like, oh, better get them back, watch them ni...</td>\n",
       "      <td>[like, oh, better get them back, watch them ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/lyric/5564463/Oh+Nelly</td>\n",
       "      <td>[here we go again, real smooth, yeah, here we ...</td>\n",
       "      <td>[here we go again, real smooth, yeah, here we ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   song  \\\n",
       "0             /lyric/5564459/Nellyville   \n",
       "1  /lyric/24660518/Gettin%27+It+Started   \n",
       "2           /lyric/5564461/Hot+in+Herre   \n",
       "3               /lyric/5564462/Dem+Boyz   \n",
       "4               /lyric/5564463/Oh+Nelly   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  [welcome to nellyville, where all newborns get...   \n",
       "1  [hey, boo, wassup?, you lookin' good, thank yo...   \n",
       "2  [hot in, so hot in here! so hot in, hot, oh!, ...   \n",
       "3  [like, oh, better get them back, watch them ni...   \n",
       "4  [here we go again, real smooth, yeah, here we ...   \n",
       "\n",
       "                                      lyrics_cleaned  \n",
       "0  [welcome to nellyville, where all newborns get...  \n",
       "1  [hey, boo, wassup?, you lookin' good, thank yo...  \n",
       "2  [hot in, so hot in here! so hot in, hot, oh!, ...  \n",
       "3  [like, oh, better get them back, watch them ni...  \n",
       "4  [here we go again, real smooth, yeah, here we ...  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#final cleaning step to remove empty list entries\n",
    "new_lyrics = []\n",
    "\n",
    "for index, row in df_songs.iterrows():\n",
    "    lyrics = row.lyrics\n",
    "    lyrics2 = [i.strip() for i in lyrics if i!=' ']\n",
    "    new_lyrics.append(lyrics2)\n",
    "    \n",
    "df_songs['lyrics_cleaned'] = new_lyrics\n",
    "df_songs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#occasionaly the algorithm predicts the same phoneme twice. this can never happen, so we remove the second occurance\n",
    "def remove_adjacent(phoneme):\n",
    "    Phoneme = phoneme.split('.')\n",
    "    p_start = [Phoneme[0]]\n",
    "    for item in Phoneme:\n",
    "        if item!=p_start[-1]:\n",
    "            p_start.append(item)\n",
    "    final_phon = '.'.join(p_start)\n",
    "    return final_phon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define function to translate any word input into a phoneme: converts to input tokens, feeds input tokens to model, obtains\n",
    "#prediction array and converts to output characters, removes back-to-back duplicates, then returns\n",
    "\n",
    "def phoneme_translator(unknowns):\n",
    "    encoder_input = np.zeros((len(unknowns), max_len),dtype='float32')\n",
    "    for i, (word) in enumerate(unknowns):\n",
    "        if len(word.split(r'.'))>1:\n",
    "            word_list = word.split(r'.')\n",
    "            big_list = []\n",
    "            for w in word_list:\n",
    "                for t, char in enumerate(w):\n",
    "                    if char in input_token_index.keys():\n",
    "                        encoder_input[i, t] = input_token_index[char]\n",
    "                    else:\n",
    "                        encoder_input[i, t] = input_token_index[' ']\n",
    "                    encoder_input[i, t+1:] = input_token_index[' ']\n",
    "                prediction = model.predict_classes(encoder_input)\n",
    "                phoneme = ' '\n",
    "                last = ''\n",
    "                for j in range(max_len):\n",
    "                    predict_token = prediction[:, j]\n",
    "                    pred_char = reverse_target_token_index[predict_token[0]]\n",
    "                    if pred_char!=last:\n",
    "                        phoneme+=pred_char.strip()\n",
    "                        last = pred_char.strip()\n",
    "                    phoneme = phoneme.strip()\n",
    "                big_list.append(phoneme)\n",
    "            phon_fin = '.'.join(big_list)\n",
    "        \n",
    "        elif len(word.split('-'))==1:\n",
    "            for t, char in enumerate(word):\n",
    "                if char in input_token_index.keys():\n",
    "                    encoder_input[i, t] = input_token_index[char]\n",
    "                else:\n",
    "                    encoder_input[i, t] = input_token_index[' ']\n",
    "                encoder_input[i, t+1:] = input_token_index[' ']\n",
    "            prediction = model.predict_classes(encoder_input)\n",
    "            phoneme = ' '\n",
    "            last = ''\n",
    "            for j in range(max_len):\n",
    "                predict_token = prediction[:, j]\n",
    "                pred_char = reverse_target_token_index[predict_token[0]]\n",
    "                if pred_char!=last:\n",
    "                    phoneme+=pred_char.strip()\n",
    "                    last = pred_char.strip()\n",
    "                phon_fin = phoneme.strip()\n",
    "            \n",
    "        else:\n",
    "            word_list = word.split('-')\n",
    "            big_list = []\n",
    "            for w in word_list:\n",
    "                if w=='uh':\n",
    "                    phoneme='ʌ'\n",
    "                else:\n",
    "                    for t, char in enumerate(w):\n",
    "                        if char in input_token_index.keys():\n",
    "                            encoder_input[i, t] = input_token_index[char]\n",
    "                        else:\n",
    "                            encoder_input[i, t] = input_token_index[' ']\n",
    "                        encoder_input[i, t+1:] = input_token_index[' ']\n",
    "                    prediction = model.predict_classes(encoder_input)\n",
    "                    phoneme = ' '\n",
    "                    last = ''\n",
    "                    for j in range(max_len):\n",
    "                        predict_token = prediction[:, j]\n",
    "                        pred_char = reverse_target_token_index[predict_token[0]]\n",
    "                        #print(pred_char)\n",
    "                        if pred_char!=last:\n",
    "                            phoneme+=pred_char.strip()\n",
    "                            last = pred_char.strip()\n",
    "                        phoneme = phoneme.strip()\n",
    "                big_list.append(phoneme)\n",
    "            phon_fin = ' '.join(big_list)\n",
    "            \n",
    "    phon_fin4 = remove_adjacent(phon_fin)\n",
    "   \n",
    "    return phon_fin4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lyrics_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27917</th>\n",
       "      <td>/lyric/21899545/Big+Heavy</td>\n",
       "      <td>[hey big daddy what you doing tonight, i got s...</td>\n",
       "      <td>[hey big daddy what you doing tonight, i got s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29976</th>\n",
       "      <td>/lyric/28836490/The+Children%27s+Song</td>\n",
       "      <td>[children hold on, to your dreams, believe in ...</td>\n",
       "      <td>[children hold on, to your dreams, believe in ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        song  \\\n",
       "27917              /lyric/21899545/Big+Heavy   \n",
       "29976  /lyric/28836490/The+Children%27s+Song   \n",
       "\n",
       "                                                  lyrics  \\\n",
       "27917  [hey big daddy what you doing tonight, i got s...   \n",
       "29976  [children hold on, to your dreams, believe in ...   \n",
       "\n",
       "                                          lyrics_cleaned  \n",
       "27917  [hey big daddy what you doing tonight, i got s...  \n",
       "29976  [children hold on, to your dreams, believe in ...  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a random sample of two songs\n",
    "df_songs_short = df_songs.sample(n=2, replace=False)\n",
    "df_songs_short.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#THIS WOULD PROCESS THE SONGS, BUT AGAIN, IT REQUIRES GPU\n",
    "\n",
    "#run through songs selected, replace identified 'problem' words, identify if the word is already in a dictionary.\n",
    "#if it is, replace it with dict version.\n",
    "#if not, predict from model and update dictionary.\n",
    "\n",
    "import re\n",
    "trans_dict = {}\n",
    "\n",
    "reg = re.compile(\"[^A-Za-z0-9]+\")\n",
    "new_songs = []\n",
    "i=0\n",
    "for index, row in df_songs_short.iterrows():\n",
    "    full_lyrics = row.lyrics\n",
    "    full_lyrics = [x for x in full_lyrics if x!=' '] #drop empty list entries\n",
    "    new_lyrics = []\n",
    "    for lyric in full_lyrics:\n",
    "        lyric = lyric.strip()\n",
    "        new_lyric = []\n",
    "        words = lyric.split(' ')\n",
    "        for word in words:\n",
    "            word = word.replace('f*ck', 'fuck')\n",
    "            word = word.replace(r'..',' ').replace('\\'','')\n",
    "            word2 = re.sub(reg, '', word) \n",
    "            if word2 in phon_dict.keys():\n",
    "                new_word = phon_dict[word2]\n",
    "                if new_word[-1]=='.':\n",
    "                    new_word=new_word[:-1]\n",
    "                new_lyric.append(new_word)\n",
    "                #print('dictionary', word2, new_word)     \n",
    "            elif word2 in trans_dict.keys():\n",
    "                new_word = trans_dict[word2]\n",
    "                new_lyric.append(new_word)\n",
    "                #print('previously learned', word2, new_word)\n",
    "            elif word2=='187':\n",
    "                new_word = 'wʌn.eɪt.sev.ən'\n",
    "                new_lyric.append(new_word)\n",
    "            elif word2=='uh':\n",
    "                new_word = 'ʌ'\n",
    "                new_lyric.append(new_word)\n",
    "            elif word2=='okay':\n",
    "                new_word = 'əʊ.keɪ'\n",
    "                new_lyric.append(new_word)\n",
    "            elif 'gucci' in word2:\n",
    "                new_word = 'ɡuːtʃi'\n",
    "                new_lyric.append(new_word)\n",
    "            else:\n",
    "                new_word = phoneme_translator([word])\n",
    "                new_word = new_word.strip().lower() \n",
    "                trans_dict.update({str(word2): new_word})\n",
    "                if len(new_word)>1 and new_word[-1]=='.':\n",
    "                    new_word = new_word[:-1]\n",
    "                new_lyric.append(new_word)\n",
    "                print('new word', word, new_word)\n",
    "        joined_lyric = ' '.join(new_lyric)\n",
    "        new_lyrics.append(joined_lyric)\n",
    "        print(\"*OLD:--->\", lyric,\"*NEW:--->\", joined_lyric)\n",
    "    new_songs.append(new_lyrics)\n",
    "    print(\"DONE: \",i, \"song:\", new_songs)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song</th>\n",
       "      <th>lyrics</th>\n",
       "      <th>lyrics_cleaned</th>\n",
       "      <th>phoneme_lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/lyric/5564459/Nellyville</td>\n",
       "      <td>[welcome to nellyville, where all newborns get...</td>\n",
       "      <td>[welcome to nellyville, where all newborns get...</td>\n",
       "      <td>[wel.kəm tuː nel.i.vl, weər ɔːl njuː.bənz ɡet ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/lyric/24660518/Gettin%27+It+Started</td>\n",
       "      <td>[hey, boo, wassup?, you lookin' good, thank yo...</td>\n",
       "      <td>[hey, boo, wassup?, you lookin' good, thank yo...</td>\n",
       "      <td>[heɪ buː wɒsʌp, juː lʊk.ɪn ɡʊd, θæŋk juː wɒts ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/lyric/5564461/Hot+in+Herre</td>\n",
       "      <td>[hot in, so hot in here! so hot in, hot, oh!, ...</td>\n",
       "      <td>[hot in, so hot in here! so hot in, hot, oh!, ...</td>\n",
       "      <td>[hɒt ɪn səʊ hɒt ɪn hɪər səʊ hɒt ɪn hɒt əʊ, dʒʌ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/lyric/5564462/Dem+Boyz</td>\n",
       "      <td>[like, oh, better get them back, watch them ni...</td>\n",
       "      <td>[like, oh, better get them back, watch them ni...</td>\n",
       "      <td>[laɪk əʊ, bet.ər ɡet ðem bæk, wɒtʃ ðem nɪɡ.ə b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/lyric/5564463/Oh+Nelly</td>\n",
       "      <td>[here we go again, real smooth, yeah, here we ...</td>\n",
       "      <td>[here we go again, real smooth, yeah, here we ...</td>\n",
       "      <td>[hɪər wiː ɡəʊ əɡen, rɪəl smuːð jeə, hɪər wiː ɡ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   song  \\\n",
       "0             /lyric/5564459/Nellyville   \n",
       "1  /lyric/24660518/Gettin%27+It+Started   \n",
       "2           /lyric/5564461/Hot+in+Herre   \n",
       "3               /lyric/5564462/Dem+Boyz   \n",
       "4               /lyric/5564463/Oh+Nelly   \n",
       "\n",
       "                                              lyrics  \\\n",
       "0  [welcome to nellyville, where all newborns get...   \n",
       "1  [hey, boo, wassup?, you lookin' good, thank yo...   \n",
       "2  [hot in, so hot in here! so hot in, hot, oh!, ...   \n",
       "3  [like, oh, better get them back, watch them ni...   \n",
       "4  [here we go again, real smooth, yeah, here we ...   \n",
       "\n",
       "                                      lyrics_cleaned  \\\n",
       "0  [welcome to nellyville, where all newborns get...   \n",
       "1  [hey, boo, wassup?, you lookin' good, thank yo...   \n",
       "2  [hot in, so hot in here! so hot in, hot, oh!, ...   \n",
       "3  [like, oh, better get them back, watch them ni...   \n",
       "4  [here we go again, real smooth, yeah, here we ...   \n",
       "\n",
       "                                      phoneme_lyrics  \n",
       "0  [wel.kəm tuː nel.i.vl, weər ɔːl njuː.bənz ɡet ...  \n",
       "1  [heɪ buː wɒsʌp, juː lʊk.ɪn ɡʊd, θæŋk juː wɒts ...  \n",
       "2  [hɒt ɪn səʊ hɒt ɪn hɪər səʊ hɒt ɪn hɒt əʊ, dʒʌ...  \n",
       "3  [laɪk əʊ, bet.ər ɡet ðem bæk, wɒtʃ ðem nɪɡ.ə b...  \n",
       "4  [hɪər wiː ɡəʊ əɡen, rɪəl smuːð jeə, hɪər wiː ɡ...  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#INSTEAD LOAD THE SONGS PROCESSED ON THE GPUs\n",
    "\n",
    "path = 'C:/Users/ian.ashmore/Desktop/data/'\n",
    "df = pd.DataFrame()\n",
    "\n",
    "for filename in glob.glob(os.path.join(path, '*.pickle')):\n",
    "    x = pd.read_pickle(filename)\n",
    "    df = pd.concat([df, x], axis=0, ignore_index=True)\n",
    "    \n",
    "df.head()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ɪt wɒz ɔːl ə driːm',\n",
       " 'lɑːst naɪt aɪ hæd ə driːm',\n",
       " 'θɔːt.s wɒz reɪ.sɪŋ θruː maɪ hed',\n",
       " 'ɪt wɒz ɔːl ə driːm',\n",
       " 'felt səʊ rɪəl tuː miː',\n",
       " 'ðɪs ɪz wɒt wɒz sed',\n",
       " 'hæd ə driːm aɪ sed baʊt huː hiː sed',\n",
       " 'baʊt bɪɡ aɪ sed ðæts bɪɡ hiː sed',\n",
       " 'dɪɡ wɒt hiː sed',\n",
       " 'prəʊ.siːd hiː sed',\n",
       " 'ɪndiːd aɪ sed səʊ briːð aɪ dɪd',\n",
       " 'aɪ siː aɪ sed dʒel.ə.si aɪ sed',\n",
       " 'ɡɒt ðiː həʊl ɪn.də.stri mæd æt miː aɪ sed',\n",
       " 'ðen baɪ sed eɪtʃ.əʊviː rɪmaɪnd jɔːself',\n",
       " 'nəʊ.bə.di bɪlt laɪk juː juː dɪzaɪnd jɔːself',\n",
       " 'aɪ əɡriː aɪ sed maɪ wʌn əv ə kaɪnd self',\n",
       " 'ɡet stəʊnd ev.ri deɪ laɪk dʒiː.əs dɪd',\n",
       " 'wɒt hiː sed aɪ sed hæz biːn sed bɪfɔːr',\n",
       " 'dʒʌst kiːp duː.ɪŋ jɔːr θɪŋ hiː sed seɪ nəʊ mɔːr',\n",
       " 'wɒz ɪt ɔːl ə driːm',\n",
       " 'wɒz ɪt ɔːl ə driːm wɒz ɪt ɔːl ə driːm',\n",
       " 'wɒz ɪt ɔːl ə driːm',\n",
       " 'wɒz ɪt ɔːl ə driːm wɒz ɪt ɔːl ə driːm',\n",
       " 'sɒlt.p.pə ænd hev.i di ʌp ɪn ðiː lɪm.əziːn',\n",
       " 'hæŋ.ɪŋ pɪk.tʃər ɒn maɪ wɔːl',\n",
       " 'aɪ let maɪ teɪp rɒk tɪl maɪ teɪp pɒpt',\n",
       " 'wɪð ðiː hæt tuː mætʃ',\n",
       " 'rɪmem.bər ræp.ɪn dʒuːk dʌ hɑː dʌ hɑː',\n",
       " 'naʊ aɪem ɪn ðiː laɪm.laɪt kɔːz aɪ raɪm taɪt',\n",
       " 'taɪm tuː ɡet peɪd bləʊ ʌp laɪk ðiː',\n",
       " 'bɔːn sɪn.ər ðiː ɒp.ə.zɪt əv ə wɪn.ər',\n",
       " 'rɪmem.bər wen aɪ juːst tuː iːt sɑː.dɪn fɔːr dɪn.ər',\n",
       " 'piːs tuː rɒn dʒiː bruː.si biːb kɪd kæp.r',\n",
       " 'fʌŋkɑː.stər fleks lʌv.bʌɡ stɑː.ski',\n",
       " 'aɪem bləʊ.ɪn ʌp laɪk juː θɔːt aɪ wʊd',\n",
       " 'ɜː ænd ɪf juː dʌnt nəʊ naʊ juː nəʊ nɪɡ.ə',\n",
       " 'wɒz ɪt ɔːl ə driːm',\n",
       " 'wɒz ɪt ɔːl ə driːm wɒz ɪt ɔːl ə driːm',\n",
       " 'wɒz ɪt ɔːl ə driːm wɒz ɪt ə driːm',\n",
       " 'wɒz ɪt ɔːl ə driːm wɒz ɪt ɔːl ə driːm',\n",
       " 'ɪt wɒz ɔːl ə driːm',\n",
       " 'ɪt wɒz ɔːl',\n",
       " 'ɪt wɒz ɔːl ə driːm',\n",
       " 'ɪt wɒz ɔːl ə driːm',\n",
       " 'ɪt wɒz ɔːl ə driːm',\n",
       " 'ɪt wɒz ɔːl',\n",
       " 'aɪ siː aɪ sed dʒel.ə.si aɪ sed',\n",
       " 'ɡɒt ðiː həʊl ɪn.də.stri mæd æt miː aɪ sed',\n",
       " 'ðen baɪ sed eɪtʃ.əʊviː rɪmaɪnd jɔːself',\n",
       " 'nəʊ.bə.di bɪlt laɪk juː juː dɪzaɪnd jɔːself',\n",
       " 'aɪ əɡriː aɪ sed maɪ wʌn əv ə kaɪnd self',\n",
       " 'ɡet stəʊnd ev.ri deɪ laɪk dʒiː.əs dɪd',\n",
       " 'wɒt hiː sed aɪ sed hæz biːn sed bɪfɔːr']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.phoneme_lyrics[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
